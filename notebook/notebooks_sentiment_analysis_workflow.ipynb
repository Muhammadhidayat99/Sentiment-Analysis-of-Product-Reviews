{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Workflow for Product Reviews\n",
    "\n",
    "This notebook covers:\n",
    "- Data Loading & Exploration\n",
    "- Text Preprocessing\n",
    "- Sentiment Analysis\n",
    "- Exploratory Data Analysis (EDA) of Sentiments\n",
    "- (Optional) Topic Modeling\n",
    "- Insight Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 1. Data Loading and Initial Exploration\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('Data/product_reviews_mock_data.csv')\n",
    "df.info()\n",
    "df.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Examine distribution of ratings\n",
    "sns.countplot(df['Rating'])\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.show()\n",
    "\n",
    "# Review text sample\n",
    "df[['ReviewText', 'Rating']].sample(5)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Preprocessing\n",
    "We'll clean the text, tokenize, remove stopwords, and perform stemming/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation & numbers\n",
    "    tokens = text.split()\n",
    "    tokens = [w for w in tokens if w not in stop_words]\n",
    "    tokens = [lemmatizer.lemmatize(w) for w in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['CleanedReview'] = df['ReviewText'].apply(preprocess)\n",
    "df[['ReviewText', 'CleanedReview']].head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment Analysis\n",
    "- We'll use VADER (suited for short, product reviews)\n",
    "- Categorize reviews as Positive, Negative, Neutral based on compound score"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(row):\n",
    "    score = sia.polarity_scores(row['CleanedReview'])['compound']\n",
    "    if score >= 0.05:\n",
    "        return 'Positive'\n",
    "    elif score <= -0.05:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment'] = df.apply(get_sentiment, axis=1)\n",
    "df[['ReviewText', 'CleanedReview', 'Sentiment']].head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis of Sentiments\n",
    "- Distribution of sentiments\n",
    "- Word clouds for positive/negative reviews\n",
    "- Sentiment by product and over time"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Distribution\n",
    "sns.countplot(df['Sentiment'], order=['Positive','Neutral','Negative'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Sentiment by Product\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.countplot(data=df, x='ProductID', hue='Sentiment', order=df['ProductID'].value_counts().index)\n",
    "plt.title('Sentiment by Product')\n",
    "plt.show()\n",
    "\n",
    "# Sentiment over time (if ReviewDate is available)\n",
    "df['ReviewDate'] = pd.to_datetime(df['ReviewDate'])\n",
    "sent_by_date = df.groupby([pd.Grouper(key='ReviewDate', freq='M'), 'Sentiment']).size().unstack().fillna(0)\n",
    "sent_by_date.plot(kind='line', figsize=(12,5), marker='o')\n",
    "plt.title('Sentiment Trend Over Time')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Wordclouds\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "for sentiment in ['Positive', 'Negative']:\n",
    "    text = ' '.join(df[df['Sentiment']==sentiment]['CleanedReview'])\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'{sentiment} Reviews WordCloud')\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Topic Modeling (Optional, on Negative Reviews)\n",
    "Discover common complaints using LDA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "neg_reviews = df[df['Sentiment']=='Negative']['CleanedReview']\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "dtm = vectorizer.fit_transform(neg_reviews)\n",
    "lda = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda.fit(dtm)\n",
    "\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{idx+1}\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Insight Generation and Recommendations\n",
    "- Summarize sentiment proportions\n",
    "- List common positive/negative themes\n",
    "- List main topics from LDA\n",
    "- Actionable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Example summary output\n",
    "print('Sentiment breakdown:')\n",
    "print(df['Sentiment'].value_counts(normalize=True))\n",
    "\n",
    "print('\\nFrequent positive words:')\n",
    "from collections import Counter\n",
    "pos_words = ' '.join(df[df['Sentiment']=='Positive']['CleanedReview']).split()\n",
    "print(Counter(pos_words).most_common(10))\n",
    "\n",
    "print('\\nFrequent negative words:')\n",
    "neg_words = ' '.join(df[df['Sentiment']=='Negative']['CleanedReview']).split()\n",
    "print(Counter(neg_words).most_common(10))\n",
    "\n",
    "print('\\nRecommendations:')\n",
    "print('- Address major pain points (e.g., \"broke easily\", \"poor quality\", \"customer service\")')\n",
    "print('- Highlight positive themes (e.g., \"amazing features\", \"wonderful experience\") in marketing')\n",
    "print('- Review topics from LDA for product improvement focus')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}